{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the LLAMA 3.2 with Pure Pytorch and Using QLoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965.1290283203125\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, get_scheduler\n",
    "from bitsandbytes.optim import Adam8bit,PagedAdam32bit\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "import time\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "    print(f\"GPU Memory Usage>>>> Allocated: {allocated:.2f} MB |||||  Reserved:  {reserved:.2f} MB:\")\n",
    "\n",
    "def flush():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "print(model.get_memory_footprint()/(1024*1024)) \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an Instruction Finetuned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d08f7d1c984727900f76360fcf6241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/30.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d27a8dac8441a3b9f994d86892fd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hardcode_qa.json:   0%|          | 0.00/61.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1151f16df0041cd8e3d888fb86bfba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"OdiaGenAI/hardcode_odia_qa_105\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'ଆପଣ କିଏ?',\n",
       " 'output': 'ମୁଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ, ଯାହାକି ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ପ୍ରଶିକ୍ଷିତ ଏକ ଭାଷା ମଡେଲ।'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset=[]\n",
    "\n",
    "for example in dataset['train']:\n",
    "    small_dataset.append({\n",
    "        \"instruction\": example['instruction'],\n",
    "        \"output\": example['output']\n",
    "    })\n",
    "    \n",
    "small_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = [\n",
    "  {\n",
    "    \"instruction\": \"Summarize the IPL 2024 season.\",\n",
    "    \"output\": \"The 2024 Indian Premier League (IPL) was a thrilling season filled with memorable moments, outstanding performances, and intense competition. Kolkata Knight Riders (KKR) emerged as the champions, defeating Sunrisers Hyderabad (SRH) in the final. The season witnessed remarkable individual performances, high-scoring matches, and competitive qualifier stages.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"Who won the IPL in 2024?\",\n",
    "    \"output\": \"Kolkata Knight Riders (KKR) won the IPL in 2024.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"Which teams played in the final of IPL 2024?\",\n",
    "    \"output\": \"Kolkata Knight Riders (KKR) and Sunrisers Hyderabad (SRH) played in the final of IPL 2024.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"Describe the performance of Kolkata Knight Riders in IPL 2024.\",\n",
    "    \"output\": \"Kolkata Knight Riders (KKR) showcased dominant performances throughout the season and emerged as the champions, defeating Sunrisers Hyderabad (SRH) in the final to clinch their third IPL title.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"What were some of the key highlights of IPL 2024?\",\n",
    "    \"output\": \"Some of the key highlights of IPL 2024 include Kolkata Knight Riders (KKR) winning the tournament, dominant performances from several teams, remarkable individual performances from both batsmen and bowlers, and many high-scoring matches.\"\n",
    "  },\n",
    "    {\n",
    "    \"instruction\": \"How were the qualifier matches in IPL 2024?\",\n",
    "    \"output\": \"The qualifier matches in IPL 2024 were very competitive. KKR and SRH both displayed strong performances to reach the final. Royal Challengers Bengaluru (RCB) and Rajasthan Royals (RR) also played well in the eliminator stages.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"What was special about the final match of IPL 2024?\",\n",
    "    \"output\": \"The final match of IPL 2024 was a highly anticipated clash between Kolkata Knight Riders and Sunrisers Hyderabad. KKR dominated the match, securing a comfortable victory and winning the IPL title.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"Did IPL 2024 have any last ball thrillers?\",\n",
    "    \"output\": \"Yes, many matches throughout the IPL 2024 season had nail-biting finishes, with last-ball thrillers and unexpected comebacks.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"How was the performance of young cricketers in IPL 2024?\",\n",
    "    \"output\": \"The IPL 2024 tournament showcased a mix of experienced players and emerging talent, with several young cricketers making a mark.\"\n",
    "  },\n",
    "  {\n",
    "      \"instruction\": \"Write a summary of IPL 2024\",\n",
    "      \"output\": \"The 2024 IPL season was a thrilling and successful tournament, filled with excitement, drama, and outstanding cricket. Kolkata Knight Riders won the title, defeating Sunrisers Hyderabad in the final.  Many matches featured high scores and nail-biting finishes.  The tournament showcased a mix of experienced and young talented players.\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lengths = [len(tokenizer(example['instruction']+example['output'])['input_ids']) for example in small_dataset]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(lengths, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Histogram of Tokenized Output Lengths\")\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'ଆପଣ କିଏ?'}, {'role': 'assistant', 'content': '\"ଆପଣ\" (Apob)  ଇ ଏ କો. ଏ. ଆ ଏ ଆ ଏ ଆ ଏ ଆ ଏ ଆ �'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "llama_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": small_dataset[0]['instruction']},\n",
    "]\n",
    "\n",
    "generated_text = llama_pipeline(messages, max_new_tokens=60, early_stopping=True)\n",
    "\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataset Object for Pytorch-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch Dataset\n",
    "class LlamaDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        question=sample['instruction']\n",
    "        answer = sample['output']\n",
    "        prompt = f'''<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'''\n",
    "        full_text = prompt+f'''{answer}<|eot_id|>'''\n",
    "\n",
    "        tokenized = tokenizer(full_text, truncation=True, add_special_tokens=False, padding=\"max_length\", max_length=300)\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "        # Tokenize just the prompt to get the split point\n",
    "        prompt_ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
    "        answer_start = len(prompt_ids)\n",
    "\n",
    "        # Mask everything before answer_start\n",
    "        labels = [-100] * answer_start + input_ids[answer_start:]\n",
    "        # Mask out padding as well\n",
    "        labels = [\n",
    "            label if token != tokenizer.pad_token_id else -100\n",
    "            for label, token in zip(labels, input_ids)\n",
    "        ]\n",
    "    \n",
    "        return {\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"attention_mask\": torch.tensor(attention_mask),\n",
    "        \"labels\": torch.tensor(labels)\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LlamaDataset(small_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    inference_mode=False,\n",
    "    use_rslora=True,\n",
    "    init_lora_weights=\"gaussian\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.norm.weight  dtype: torch.float16  requirs grad:  False\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0],' dtype:',param[1].dtype, ' requirs grad: ',param[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.norm.weight  dtype: torch.float16  requirs grad:  False\n"
     ]
    }
   ],
   "source": [
    "# Now manually move LoRA params to bf16\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora_\" in name:\n",
    "        param.data = param.data.to(torch.bfloat16)\n",
    "        if param.requires_grad:\n",
    "            param.grad = None  # Reset grads just in case\n",
    "\n",
    "for param in model.named_parameters():\n",
    "    print(param[0],' dtype:',param[1].dtype, ' requirs grad: ',param[1].requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the LLAMA model on a single text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eval(model,idx=5,disable_lora=False):\n",
    "    \n",
    "    model.config.use_cache = True\n",
    "    sample=small_dataset[idx]\n",
    "    question=sample['instruction']\n",
    "    answer = sample['output']\n",
    "    chat_template = f'''<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'''\n",
    "    inputs = tokenizer(chat_template , return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "    # print(prompt)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    if disable_lora:\n",
    "        with model.disable_adapter():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                do_sample=True,\n",
    "                max_new_tokens=200,\n",
    "                repetition_penalty=1.3,\n",
    "                temperature=0.7,         # Optional: smooth randomness\n",
    "                top_k=50,                # Optional: top-k sampling\n",
    "                top_p=0.9                # Optional: nucleus sampling\n",
    "            )\n",
    "    else:\n",
    "        output = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=200,\n",
    "        repetition_penalty=1.3,\n",
    "        temperature=0.7,         # Optional: smooth randomness\n",
    "        top_k=50,                # Optional: top-k sampling\n",
    "        top_p=0.9                # Optional: nucleus sampling\n",
    "        )\n",
    "\n",
    "    processed_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'ଆପଣ କିଏ?',\n",
       " 'output': 'ମୁଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ ନାମକ ଏକ ଭାଷା ମଡେଲ୍ ଏବଂ ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ପ୍ରଶିକ୍ଷିତ ହୋଇଛି।'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ଆପଣ କିଏ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\"apa la apna khana \" \n",
      "\n",
      "“apa” অর্থ - “সাধৃতে”\n",
      "“Apa La Apa Khane” \n",
      "- (Apan) – A pan\n",
      "(Alap Ana) -(లే దా)\n",
      "(Lapan Alupani, a lepan alupni or lopan al upi i.e. Lopa lopane and etc.)\n",
      "\n",
      "   મૂળભોગ<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "pred = generate_eval(model=model,idx=4,disable_lora=False)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Usage>>>> Allocated: 1052.81 MB |||||  Reserved:  1548.00 MB:\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()\n",
    "flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(running_loss)\n\u001b[1;32m---> 40\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mglobal_step\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     42\u001b[0m print_gpu_utilization()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "gradient_accumulation_steps = 4\n",
    "max_steps=500\n",
    "max_loss = 1e9\n",
    "\n",
    "from torch.optim import AdamW\n",
    "# Define optimizer\n",
    "params_to_optimize = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "optimizer = AdamW(params_to_optimize, lr=1e-5)\n",
    "# optimizer = Adam8bit(params_to_optimize, lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "\n",
    "global_step= 0\n",
    "running_loss = []\n",
    "\n",
    "while global_step< max_steps:\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        model.config.use_cache = False\n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch['input_ids'].to('cuda'), attention_mask=batch['attention_mask'].to('cuda'), labels=batch['labels'].to('cuda'))\n",
    "        loss = outputs.loss\n",
    "        running_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        global_step += 1\n",
    "        if global_step >= max_steps:\n",
    "            break\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(running_loss)\n",
    "        plt.title(f\"Epoch {global_step + 1}/{max_steps}, Loss: {loss.item():.4f}\")\n",
    "        plt.show()\n",
    "        print_gpu_utilization()\n",
    " \n",
    "        \n",
    "flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "ଆପଣ କିଏ?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "ମୋ ବଂ-ସଞ଍ ବଁ ଅଲିଭ୍ ନାମରେ ଫଳିତ ଓଡ଼-ଜେନ-ଏ.ଆଈ ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ଚାଟୁକାନଙ୍କ ମୁଁ ଓଡିଆ-ଜ�\n"
     ]
    }
   ],
   "source": [
    "pred = generate_eval(model=model,idx=4,disable_lora=False)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'ଆପଣ କିଏ?',\n",
       " 'output': 'ମୁଁ ଅଲିଭ୍ ଏକ ଚାଟ୍ବଟ୍ ଆସିଷ୍ଟାଣ୍ଟ ନାମକ ଏକ ଭାଷା ମଡେଲ୍ ଏବଂ ଓଡିଆ-ଜେନ-ଏ.ଆଇ. ଗବେଷକମାନଙ୍କ ଦ୍ୱାରା ପ୍ରଶିକ୍ଷିତ ହୋଇଛି।'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the LoRA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('adapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading back the model and adding the LoRA adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965.1290283203125\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, get_scheduler,pipeline\n",
    "from bitsandbytes.optim import Adam8bit,PagedAdam32bit\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "import time\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "    print(f\"GPU Memory Usage>>>> Allocated: {allocated:.2f} MB |||||  Reserved:  {reserved:.2f} MB:\")\n",
    "\n",
    "def flush():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "print(model.get_memory_footprint()/(1024*1024)) \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the adapter into the base model\n",
    "model = PeftModel.from_pretrained(model, 'adapter')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tatsu-lab/alpaca\")\n",
    "# Select only the first 200 rows\n",
    "small_dataset = []\n",
    "for i, example in enumerate(dataset['train']):\n",
    "    if i >= 200:# I only kept 200 rows\n",
    "        break\n",
    "    small_dataset.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Summarize the IPL 2024 season.',\n",
       " 'output': 'The 2024 Indian Premier League (IPL) was a thrilling season filled with memorable moments, outstanding performances, and intense competition. Kolkata Knight Riders (KKR) emerged as the champions, defeating Sunrisers Hyderabad (SRH) in the final. The season witnessed remarkable individual performances, high-scoring matches, and competitive qualifier stages.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n",
      "c:\\Users\\User\\miniconda3\\envs\\torch_env\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian Premier League (IPL) is an ongoing and dynamic competition, and the outcome of the tournament can change rapidly. As of my knowledge cutoff in December 2023, the teams that were likely to perform well in the upcoming season included the Royal Challengers Bangalore, the Chennai Super Kings,\n"
     ]
    }
   ],
   "source": [
    "llama_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who is gonna win IPL?\"}\n",
    "]\n",
    "\n",
    "generated_text = llama_pipeline(messages, max_new_tokens=60, early_stopping=True)\n",
    "\n",
    "print(generated_text[0]['generated_text'][-1]['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
