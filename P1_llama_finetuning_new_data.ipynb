{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Usage>>>> Allocated: 382.00 MB |||||  Reserved:  382.00 MB:\n",
      "Original dtype: torch.float32\n",
      "GPU Memory Usage>>>> Allocated: 53.96 MB |||||  Reserved:  70.00 MB:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "    print(f\"GPU Memory Usage>>>> Allocated: {allocated:.2f} MB |||||  Reserved:  {reserved:.2f} MB:\")\n",
    "\n",
    "def flush():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Create a simple 10000x10000 float32 tensor\n",
    "tensor_fp32 = torch.randn(10000, 10000, dtype=torch.float32).cuda()\n",
    "print_gpu_utilization()\n",
    "\n",
    "print(f\"Original dtype: {tensor_fp32.dtype}\")\n",
    "\n",
    "# Quantize to 8-bit using bitsandbytes\n",
    "# bnb.nn.Int8Params is designed to store tensors in int8\n",
    "quantized_tensor = bnb.functional.quantize_4bit(tensor_fp32)\n",
    "\n",
    "del tensor_fp32\n",
    "flush()\n",
    "\n",
    "print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: tensor([[-0.1755,  0.7386,  0.2404,  ..., -1.2353, -0.3529,  0.1440],\n",
      "        [-0.0735, -0.9209,  0.9531,  ...,  0.1660,  1.7103,  0.2442],\n",
      "        [ 1.1087,  0.7899,  0.1461,  ...,  0.3863,  1.4779,  1.2505],\n",
      "        ...,\n",
      "        [ 0.9259, -0.0159, -0.3909,  ..., -0.4151,  0.3180, -0.3785],\n",
      "        [-1.0048,  0.8912,  1.4854,  ...,  0.9281,  0.7023, -0.3175],\n",
      "        [ 0.4238, -1.1607,  0.3622,  ..., -0.7286,  0.3647,  1.2309]],\n",
      "       device='cuda:0') \n",
      "\n",
      "Quantized: tensor([[148],\n",
      "        [110],\n",
      "        [ 17],\n",
      "        ...,\n",
      "        [ 23],\n",
      "        [220],\n",
      "        [ 98]], device='cuda:0', dtype=torch.uint8) \n",
      "\n",
      "Dequantized: tensor([[-0.0129,  0.8258,  0.4129,  ..., -1.1632, -0.3877,  0.0121],\n",
      "        [-0.0121, -0.7755,  0.7755,  ...,  0.0133,  1.6977,  0.4244],\n",
      "        [ 1.2733,  0.8488,  0.0133,  ...,  0.3926,  1.5705,  1.1779],\n",
      "        ...,\n",
      "        [ 1.0470, -0.0164, -0.5235,  ..., -0.4418,  0.4418, -0.4418],\n",
      "        [-0.8837,  0.8837,  1.3255,  ...,  0.7940,  0.7940, -0.3970],\n",
      "        [ 0.3970, -1.1910,  0.3970,  ..., -0.6726,  0.3363,  1.3451]],\n",
      "       device='cuda:0') \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor_fp32 = torch.randn(100, 100, dtype=torch.float32).cuda()\n",
    "print(f\"Original: {tensor_fp32} \\n\")\n",
    "\n",
    "quantized_tensor = bnb.functional.quantize_4bit(tensor_fp32)\n",
    "print(f\"Quantized: {quantized_tensor[0]} \\n\")\n",
    "\n",
    "dequantized_tensor = bnb.functional.dequantize_4bit(quantized_tensor[0],quantized_tensor[1])\n",
    "print(f\"Dequantized: {dequantized_tensor} \\n\")\n",
    "\n",
    "# Move everything to CPU for easier plotting\n",
    "tensor_fp32_cpu = tensor_fp32.detach().cpu().flatten()\n",
    "quantized_tensor_cpu = quantized_tensor[0].detach().cpu().flatten()\n",
    "dequantized_tensor_cpu = dequantized_tensor.detach().cpu().flatten()\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(tensor_fp32_cpu.numpy(), bins=100, color='blue', alpha=0.7)\n",
    "plt.title('Original Tensor (FP32)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(quantized_tensor_cpu.numpy(), bins=16, color='green', alpha=0.7)\n",
    "plt.title('Quantized Tensor (4-bit)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.hist(dequantized_tensor_cpu.numpy(), bins=100, color='red', alpha=0.7)\n",
    "plt.title('Dequantized Tensor')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Rank Adaptation (LoRA)\n",
    "![LoRA Concept](./images/lora.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters to optimize: 1000000\n",
      "LoRA parameters to optimize: 32000\n",
      "3.20% of total parameters\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn(1000, 1000, dtype=torch.float32).cuda()\n",
    "print(f'Total parameters to optimize: {torch.numel(W)}')\n",
    "\n",
    "rank = 16\n",
    "A = torch.randn(1000, rank, dtype=torch.float32).cuda()\n",
    "B = torch.randn(rank, 1000, dtype=torch.float32).cuda()\n",
    "print(f'LoRA parameters to optimize: {torch.numel(A)+torch.numel(B)}')\n",
    "print(f'{(torch.numel(A)+torch.numel(B))/torch.numel(W)*100:.2f}% of total parameters')\n",
    "\n",
    "# Compute W = A @ B\n",
    "W_lora = A @ B\n",
    "print(torch.numel(W_lora))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the LLAMA 3.2 with Pure Pytorch and Using QLoRA\n",
    "\n",
    "![QLORA](images/schema_QLORA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965.1290283203125\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, get_scheduler\n",
    "from bitsandbytes.optim import Adam8bit,PagedAdam32bit\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "import time\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "    print(f\"GPU Memory Usage>>>> Allocated: {allocated:.2f} MB |||||  Reserved:  {reserved:.2f} MB:\")\n",
    "\n",
    "def flush():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "print(model.get_memory_footprint()/(1024*1024)) \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load an Instruction Finetuned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "# dataset = load_dataset(\"OdiaGenAI/hardcode_odia_qa_105\")\n",
    "dataset = load_dataset('OdiaGenAI/odia_domain_context_train_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': '      ?',\n",
       " 'output': '                    ,         \\n           ,  ,           ,        ,        \\n                    ,       -   \\n                '}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset=[]\n",
    "\n",
    "for example in dataset['train']:\n",
    "    small_dataset.append({\n",
    "        \"instruction\": example['instruction'],\n",
    "        \"output\": example['output']\n",
    "    })\n",
    "    \n",
    "small_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = [\n",
    "  {\n",
    "    \"instruction\": \"Summarize the IPL 2024 season.\",\n",
    "    \"output\": \"The 2024 Indian Premier League (IPL) was a thrilling season filled with memorable moments, outstanding performances, and intense competition. Kolkata Knight Riders (KKR) emerged as the champions, defeating Sunrisers Hyderabad (SRH) in the final. The season witnessed remarkable individual performances, high-scoring matches, and competitive qualifier stages.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"Who won the IPL in 2024?\",\n",
    "    \"output\": \"Kolkata Knight Riders (KKR) won the IPL in 2024.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"Which teams played in the final of IPL 2024?\",\n",
    "    \"output\": \"Kolkata Knight Riders (KKR) and Sunrisers Hyderabad (SRH) played in the final of IPL 2024.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"Describe the performance of Kolkata Knight Riders in IPL 2024.\",\n",
    "    \"output\": \"Kolkata Knight Riders (KKR) showcased dominant performances throughout the season and emerged as the champions, defeating Sunrisers Hyderabad (SRH) in the final to clinch their third IPL title.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"What were some of the key highlights of IPL 2024?\",\n",
    "    \"output\": \"Some of the key highlights of IPL 2024 include Kolkata Knight Riders (KKR) winning the tournament, dominant performances from several teams, remarkable individual performances from both batsmen and bowlers, and many high-scoring matches.\"\n",
    "  },\n",
    "    {\n",
    "    \"instruction\": \"How were the qualifier matches in IPL 2024?\",\n",
    "    \"output\": \"The qualifier matches in IPL 2024 were very competitive. KKR and SRH both displayed strong performances to reach the final. Royal Challengers Bengaluru (RCB) and Rajasthan Royals (RR) also played well in the eliminator stages.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"What was special about the final match of IPL 2024?\",\n",
    "    \"output\": \"The final match of IPL 2024 was a highly anticipated clash between Kolkata Knight Riders and Sunrisers Hyderabad. KKR dominated the match, securing a comfortable victory and winning the IPL title.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"Did IPL 2024 have any last ball thrillers?\",\n",
    "    \"output\": \"Yes, many matches throughout the IPL 2024 season had nail-biting finishes, with last-ball thrillers and unexpected comebacks.\"\n",
    "  },\n",
    "  {\n",
    "    \"instruction\": \"How was the performance of young cricketers in IPL 2024?\",\n",
    "    \"output\": \"The IPL 2024 tournament showcased a mix of experienced players and emerging talent, with several young cricketers making a mark.\"\n",
    "  },\n",
    "  {\n",
    "      \"instruction\": \"Write a summary of IPL 2024\",\n",
    "      \"output\": \"The 2024 IPL season was a thrilling and successful tournament, filled with excitement, drama, and outstanding cricket. Kolkata Knight Riders won the title, defeating Sunrisers Hyderabad in the final.  Many matches featured high scores and nail-biting finishes.  The tournament showcased a mix of experienced and young talented players.\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lengths = [len(tokenizer(example['instruction']+example['output'])['input_ids']) for example in small_dataset]\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(lengths, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Histogram of Tokenized Output Lengths\")\n",
    "plt.xlabel(\"Number of tokens\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "/home/mohan.dash/miniconda3/envs/diffusion_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Summarize the IPL 2024 season.'}, {'role': 'assistant', 'content': \"I'm happy to provide a summary of the IPL 2024 season. However, please note that I'm a large language model, I don't have have access to real-time information or the latest updates. My training data only goes up to 2022.\\n\\nThat being said, I can provide\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "llama_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": small_dataset[0]['instruction']},\n",
    "]\n",
    "\n",
    "generated_text = llama_pipeline(messages, max_new_tokens=60, early_stopping=True)\n",
    "\n",
    "print(generated_text[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataset Object for Pytorch-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch Dataset\n",
    "class LlamaDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        question=sample['instruction']\n",
    "        answer = sample['output']\n",
    "        prompt = f'''<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'''\n",
    "        full_text = prompt+f'''{answer}<|eot_id|>'''\n",
    "\n",
    "        tokenized = tokenizer(full_text, truncation=True, add_special_tokens=False, padding=\"max_length\", max_length=200)\n",
    "\n",
    "        input_ids = tokenized[\"input_ids\"]\n",
    "        attention_mask = tokenized[\"attention_mask\"]\n",
    "\n",
    "        # Tokenize just the prompt to get the split point\n",
    "        prompt_ids = tokenizer(prompt, add_special_tokens=False)[\"input_ids\"]\n",
    "        answer_start = len(prompt_ids)\n",
    "\n",
    "        # Mask everything before answer_start\n",
    "        labels = [-100] * answer_start + input_ids[answer_start:]\n",
    "        # Mask out padding as well\n",
    "        labels = [\n",
    "            label if token != tokenizer.pad_token_id else -100\n",
    "            for label, token in zip(labels, input_ids)\n",
    "        ]\n",
    "    \n",
    "        return {\n",
    "        \"input_ids\": torch.tensor(input_ids),\n",
    "        \"attention_mask\": torch.tensor(attention_mask),\n",
    "        \"labels\": torch.tensor(labels)\n",
    "    }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LlamaDataset(small_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    inference_mode=False,\n",
    "    use_rslora=True,\n",
    "    init_lora_weights=\"gaussian\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.0.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.1.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.2.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.3.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.4.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.5.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.6.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.7.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.8.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.9.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.10.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.11.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.12.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.13.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.14.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight  dtype: torch.float32  requirs grad:  True\n",
      "base_model.model.model.layers.15.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.norm.weight  dtype: torch.float16  requirs grad:  False\n"
     ]
    }
   ],
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0],' dtype:',param[1].dtype, ' requirs grad: ',param[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.embed_tokens.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.0.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.0.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.1.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.1.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.2.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.2.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.3.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.3.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.4.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.4.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.5.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.5.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.6.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.6.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.7.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.7.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.8.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.8.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.9.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.9.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.10.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.10.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.11.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.11.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.12.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.12.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.13.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.13.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.14.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.14.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.up_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.down_proj.base_layer.weight  dtype: torch.uint8  requirs grad:  False\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight  dtype: torch.bfloat16  requirs grad:  True\n",
      "base_model.model.model.layers.15.input_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.layers.15.post_attention_layernorm.weight  dtype: torch.float16  requirs grad:  False\n",
      "base_model.model.model.norm.weight  dtype: torch.float16  requirs grad:  False\n"
     ]
    }
   ],
   "source": [
    "# Now manually move LoRA params to bf16\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora_\" in name:\n",
    "        param.data = param.data.to(torch.bfloat16)\n",
    "        if param.requires_grad:\n",
    "            param.grad = None  # Reset grads just in case\n",
    "\n",
    "for param in model.named_parameters():\n",
    "    print(param[0],' dtype:',param[1].dtype, ' requirs grad: ',param[1].requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the LLAMA model on a single text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eval(model,idx=5,disable_lora=False):\n",
    "    \n",
    "    model.config.use_cache = True\n",
    "    sample=small_dataset[idx]\n",
    "    question=sample['instruction']\n",
    "    answer = sample['output']\n",
    "    chat_template = f'''<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n'''\n",
    "    inputs = tokenizer(chat_template , return_tensors=\"pt\", add_special_tokens=False).to(device)\n",
    "    # print(prompt)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "    if disable_lora:\n",
    "        with model.disable_adapter():\n",
    "            output = model.generate(\n",
    "                **inputs,\n",
    "                do_sample=True,\n",
    "                max_new_tokens=60,\n",
    "                repetition_penalty=1.3,\n",
    "                temperature=0.7,         # Optional: smooth randomness\n",
    "                top_k=50,                # Optional: top-k sampling\n",
    "                top_p=0.9                # Optional: nucleus sampling\n",
    "            )\n",
    "    else:\n",
    "        output = model.generate(\n",
    "        **inputs,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=60,\n",
    "        repetition_penalty=1.3,\n",
    "        temperature=0.7,         # Optional: smooth randomness\n",
    "        top_k=50,                # Optional: top-k sampling\n",
    "        top_p=0.9                # Optional: nucleus sampling\n",
    "        )\n",
    "\n",
    "    processed_text = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'What were some of the key highlights of IPL 2024?',\n",
       " 'output': 'Some of the key highlights of IPL 2024 include Kolkata Knight Riders (KKR) winning the tournament, dominant performances from several teams, remarkable individual performances from both batsmen and bowlers, and many high-scoring matches.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What were some of the key highlights of IPL 2024?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "I'm happy to provide general information about Indian Premier League (IPL) but could not find any details on an upcoming season called \"IPL 2024\". The most recent edition is Season-12, which was scheduled for April-May and June-July in India. If you are looking at\n"
     ]
    }
   ],
   "source": [
    "pred = generate_eval(model=model,idx=4,disable_lora=False)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Usage>>>> Allocated: 3441.64 MB |||||  Reserved:  6432.00 MB:\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()\n",
    "flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Usage>>>> Allocated: 1196.79 MB |||||  Reserved:  6432.00 MB:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), attention_mask\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), labels\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m---> 29\u001b[0m running_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "gradient_accumulation_steps = 4\n",
    "max_steps=500\n",
    "max_loss = 1e9\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from bitsandbytes.optim import Adam8bit,PagedAdam32bit\n",
    "# Define optimizer\n",
    "params_to_optimize = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "# optimizer = AdamW(params_to_optimize, lr=1e-4)\n",
    "# optimizer = Adam8bit(params_to_optimize, lr=1e-4)\n",
    "optimizer = PagedAdam32bit(params_to_optimize, lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "\n",
    "global_step= 0\n",
    "running_loss = []\n",
    "\n",
    "while global_step< max_steps:\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        model.config.use_cache = False\n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch['input_ids'].to('cuda'), attention_mask=batch['attention_mask'].to('cuda'), labels=batch['labels'].to('cuda'))\n",
    "        loss = outputs.loss\n",
    "        running_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        \n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        global_step += 1\n",
    "        if global_step >= max_steps:\n",
    "            break\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(running_loss)\n",
    "        plt.title(f\"Epoch {global_step + 1}/{max_steps}, Loss: {loss.item():.4f}\")\n",
    "        plt.show()\n",
    "        print_gpu_utilization()\n",
    " \n",
    "        \n",
    "flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Usage>>>> Allocated: 1858.56 MB |||||  Reserved:  2478.00 MB:\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|> <|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What were some of the key highlights of IPL 2024?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Some of the key highlights of IPL 2024 include Kolkata Knight Riders (KKR) winning the title, dominant performances from several teams and many high-scoring matches. Many individual players also showcased remarkable performances to help their teams win the championship. The tournament witnessed significant contributions from both batsmen and bow\n"
     ]
    }
   ],
   "source": [
    "pred = generate_eval(model=model,idx=4,disable_lora=False)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'What were some of the key highlights of IPL 2024?',\n",
       " 'output': 'Some of the key highlights of IPL 2024 include Kolkata Knight Riders (KKR) winning the tournament, dominant performances from several teams, remarkable individual performances from both batsmen and bowlers, and many high-scoring matches.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the LoRA Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 2048)\n",
       "        (layers): ModuleList(\n",
       "          (0-15): 16 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=512, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=512, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=2048, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('adapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading back the model and adding the LoRA adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "965.1290283203125\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, get_scheduler,pipeline\n",
    "from bitsandbytes.optim import Adam8bit,PagedAdam32bit\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "import time\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "    print(f\"GPU Memory Usage>>>> Allocated: {allocated:.2f} MB |||||  Reserved:  {reserved:.2f} MB:\")\n",
    "\n",
    "def flush():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "print(model.get_memory_footprint()/(1024*1024)) \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(DEFAULT_MODEL, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(128256, 3072)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=3072, out_features=8192, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=8192, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=8192, out_features=16, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=16, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (rotary_emb): LlamaRotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the adapter into the base model\n",
    "model = PeftModel.from_pretrained(model, 'adapter')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Summarize the IPL 2024 season.',\n",
       " 'output': 'The 2024 Indian Premier League (IPL) was a thrilling season filled with memorable moments, outstanding performances, and intense competition. Kolkata Knight Riders (KKR) emerged as the champions, defeating Sunrisers Hyderabad (SRH) in the final. The season witnessed remarkable individual performances, high-scoring matches, and competitive qualifier stages.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n",
      "c:\\Users\\User\\miniconda3\\envs\\torch_env\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian Premier League (IPL) is an ongoing and dynamic competition, and the outcome of the tournament can change rapidly. As of my knowledge cutoff in December 2023, the teams that were likely to perform well in the upcoming season included the Royal Challengers Bangalore, the Chennai Super Kings,\n"
     ]
    }
   ],
   "source": [
    "llama_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who is gonna win IPL?\"}\n",
    "]\n",
    "\n",
    "generated_text = llama_pipeline(messages, max_new_tokens=60, early_stopping=True)\n",
    "\n",
    "print(generated_text[0]['generated_text'][-1]['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
