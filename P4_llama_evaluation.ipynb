{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53823db9358046b7b6ebb98961597033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2095.841064453125\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, get_scheduler\n",
    "from bitsandbytes.optim import Adam8bit,PagedAdam32bit\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "import torch\n",
    "from IPython.display import  clear_output\n",
    "import time\n",
    "import gc,os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from evaluation_utlis import rouge_bleu_score\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "DEFAULT_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "TOKENIZER_PATH = DEFAULT_MODEL#\"llama_odia_tokenizer\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "    )\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    DEFAULT_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    use_safetensors=True,\n",
    "    device_map=device,\n",
    ")\n",
    "\n",
    "print(model.get_memory_footprint()/(1024*1024)) \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, use_safetensors=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def flush():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "# dataset = load_dataset(\"OdiaGenAI/hardcode_odia_qa_105\")\n",
    "dataset = load_dataset('OdiaGenAI/odia_domain_context_train_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohan.dash/miniconda3/envs/diffusion_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/mohan.dash/miniconda3/envs/diffusion_env/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "res = rouge_bleu_score(model,tokenizer,dataset['train'],device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'ଓଡ଼ିଶାର ଅର୍ଥନୀତି ଉପରେ ପର୍ଯ୍ୟଟନର କିଭଳି ପ୍ରଭାବ ପଡ଼ିଛି?',\n",
       " 'input': '',\n",
       " 'output': 'ବିଗତ କିଛି ବର୍ଷ ମଧ୍ୟରେ ପର୍ଯ୍ୟଟନ ଶିଳ୍ପ ଦ୍ୱାରା ଓଡ଼ିଶାର ଅର୍ଥନୀତି ବ୍ୟାପକ ଭାବେ ପ୍ରଭାବିତ ହୋଇଛି। ରାଜ୍ୟରେ ପ୍ରାକୃତିକ ସୌନ୍ଦର୍ଯ୍ୟ ଏବଂ ସାଂସ୍କୃତିକ ଐତିହ୍ୟ ସ୍ଥାନ ରହିଛି, ଯାହା ଦେଶ ଏବଂ ଦେଶ ବାହାରର ପର୍ଯ୍ୟଟକଙ୍କ ପାଇଁ ଆକର୍ଷଣୀୟ ହୋଇପାରିଛି।\\nପର୍ଯ୍ୟଟନ କ୍ଷେତ୍ରରେ କାର୍ଯ୍ୟ କରୁଥିବା ଲୋକମାନଙ୍କ ପାଇଁ ନିଯୁକ୍ତି ସୁଯୋଗ ଏବଂ ଆୟ ବୃଦ୍ଧି ପାଇଛି, ଯେଉଁଥିରେ ଆତିଥ୍ୟ, ଟୁର ଅପରେଟର ଏବଂ ପରିବହନ ଶିଳ୍ପ ସାମିଲ ରହିଛି। ପର୍ଯ୍ୟଟନ ଶିଳ୍ପ ସ୍ଥାନୀୟ ଖାଦ୍ୟ, ହସ୍ତଶିଳ୍ପ ଏବଂ ସାଂସ୍କୃତିକ ଗତିବିଧିକୁ ପ୍ରୋତ୍ସାହିତ କରିବାରେ ସହାୟତା କରିଛି, ଯାହାକି ଓଡ଼ିଶାର ସାମଗ୍ରିକ ଅର୍ଥନୀତି ଉପରେ ସକାରାତ୍ମକ ପ୍ରଭାବ ପକାଇଛି।\\nପର୍ଯ୍ୟଟକମାନଙ୍କ ପାଇଁ ଉତ୍ତମ ଅନୁଭୂତି ସୁନିଶ୍ଚିତ କରିବା ପାଇଁ ଭିତ୍ତିଭୂମି ବିକାଶ ଉପରେ ମଧ୍ୟ ସରକାର ଗୁରୁତ୍ୱ ଦେଉଛନ୍ତି। ସଡ଼କ ଏବଂ ସାର୍ବଜନୀନ ପରିବହନ ବ୍ୟବସ୍ଥାରେ ସୁଧାର କରାଯାଇଛି, ଯେତେବେଳେ କି ରାଜ୍ୟର ଅନେକ କ୍ଷେତ୍ରରେ ବିଭିନ୍ନ ଇକୋ-ଟୁରିଜମ ପ୍ରକଳ୍ପର ବିକାଶ କରାଯାଇଛି।\\nଶେଷରେ ପର୍ଯ୍ୟଟନ ଓଡ଼ିଶାର ଆର୍ଥିକ ବିକାଶକୁ ତ୍ୱରାନ୍ୱିତ କରିବାରେ ଗୁରୁତ୍ୱପୂର୍ଣ୍ଣ ଭୂମିକା ନିର୍ବାହ କରିଛି ଏବଂ ରାଜ୍ୟବାସୀଙ୍କ ପାଇଁ ଅନେକ ଲାଭ ଆଣିପାରିଛି।'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.25, 'rouge2': 0.0, 'rougeL': 0.25, 'rougeLsum': 0.25}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge.compute(predictions=['ଓଡ଼ିଶାର ଅର୍ଥନୀତି ଉପରେ ପର୍ଯ୍ୟଟନର କିଭଳି ପ୍ରଭାବ ପଡ଼ିଛି?'], \n",
    "              references=['ଓଡ଼ିଶାର '],\n",
    "              tokenizer=lambda x: x.split(),  # Tokenize by whitespace only\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
